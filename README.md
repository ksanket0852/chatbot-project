# LLM-Based Chatbot App

This project is a chatbot application using Groq API and Ollama for local LLM inference.

## Features
- Chatbot using Groq's API with meta-llama/llama-4 model
- Local inference using Ollama API
- Gradio web UI for chat interface

## Setup
1. Clone the repo
2. Install dependencies: `pip install -r requirements.txt`
3. Add `.env` file with your API key:

4. Run the app: `python app.py`

## Demo
[Live demo link](https://huggingface.co/spaces/enayat11/chatbot-grok)
